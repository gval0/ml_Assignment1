# სახლის ფასების პროგნოზირება

## Kaggle-ის კონკურსის მოკლე მიმოხილვა
ეს პროექტი წარმოადგენს Kaggle-ის კონკურსის "House Prices: Advanced Regression Techniques" გადაწყვეტას. კონკურსის მიზანია სახლების ფასების პროგნოზირება სხვადასხვა მახასიათებლების საფუძველზე. მონაცემთა ნაკრები შეიცავს 80 ცვლადს, რომლებიც აღწერს სახლების თითქმის ყველა ასპექტს, როგორიცაა: ფართობი, ოთახების რაოდენობა, გარაჟის ტიპი, სახურავის მასალა და ა.შ.

## ჩემი მიდგომა პრობლემის გადასაჭრელად
პრობლემის გადასაჭრელად გამოვიყენე შემდეგი მეთოდოლოგია:

1. **მონაცემთა წინასწარი დამუშავება** - ნაკლული მნიშვნელობების შევსება, გამორიცხვა და კატეგორიული ცვლადების რიცხვითში გადაყვანა
2. **ნიშნების შერჩევა** - დომეინის ცოდნაზე დაყრდნობით და სტატისტიკური მეთოდებით
3. **გამორიცხული წერტილების დამუშავება** - Z-score გამოყენებით
4. **სხვადასხვა რეგრესიული მოდელების შედარება** - ჩავატარე ექსპერიმენტები under-fitting, properly-fitted და over-fitting მოდელებზე
5. **MLflow-ის გამოყენება** - ექსპერიმენტების ასახვისთვის

## რეპოზიტორიის სტრუქტურა
- `model_experiment_data_exploration.ipynb` - Jupyter ნოუთბუქი დატის გამოსაკვლევად
- `model_experiment.ipynb` - ძირითადი Jupyter ნოუთბუქი, რომელიც ხდება დატას დამუშავება და მოდელების შერჩევა
- `model_inference.ipynb` - ძირითადი Jupyter ნოუთბუქი, რომელიც ხდება test set ზე პროგნოზი საუკეთესო მოდელით
- `train.csv` - ტრენირების მონაცემები
- `test.csv` - ტესტირების მონაცემები
- `README.md` - readme ფაილი


## Feature Engineering

### კატეგორიული ცვლადების რიცხვითში გადაყვანა
კატეგორიული ცვლადების დასამუშავებლად გამოვიყენე ორდინალური კოდირება. თითოეული უნიკალური კატეგორია დალაგდა ანბანური წესით და შემდეგ მიენიჭა რიცხვითი მნიშვნელობა:

### Nan მნიშვნელობების დამუშავება
ნაკლული მნიშვნელობების შესავსებად გამოვიყენე მედიანით შევსების მეთოდი

### Cleaning მიდგომები
მონაცემთა გაწმენდის პროცესში გამოვიყენე შემდეგი მიდგომები:
- იდენტიფიკატორის სვეტის წაშლა (Id)
- იმ სვეტების წაშლა, სადაც მნიშვნელობების 90% ერთნაირია
- იმ სვეტების წაშლა, სადაც 95%-ზე მეტი მნიშვნელობა ნაკლულია
- იმ სვეტების წაშლა, სადაც 90%-ზე მეტი მნიშვნელობა ნულია

## Feature Selection

### გამოყენებული მიდგომები და მათი შეფასება
Feature შერჩევისთვის გამოვიყენე დომენის ცოდნაზე დაფუძნებული მიდგომა. ფართო ნიშნების სიმრავლიდან შევარჩიე ყველაზე მნიშვნელოვანი ცვლადები შემდეგი კატეგორიებიდან:

1. **სტრუქტურული მახასიათებლები** - GrLivArea (საცხოვრებელი ფართობი)
2. **ხარისხის მახასიათებლები** - OverallQual (საერთო ხარისხი)
3. **დროის მახასიათებლები** - YearBuilt (აშენების წელი)
4. **რაოდენობრივი მახასიათებლები** - BedroomAbvGr (საძინებლების რაოდენობა), FullBath (სრული აბაზანების რაოდენობა)
5. **გარაჟის მახასიათებლები** - GarageCars (გარაჟში მანქანების რაოდენობა)
6. **გარე მახასიათებლები** - LotArea (ნაკვეთის ფართობი)
7. **კატეგორიული მახასიათებლები** - BldgType (შენობის ტიპი), SaleCondition (გაყიდვის პირობები)

საბოლოოდ, ჩვენი ანალიზისთვის შევარჩიე 9 ყველაზე მნიშვნელოვანი ცვლადი საწყისი 79-დან.

## Outliers დამუშავება

წერტილების (outliers) იდენტიფიცირებისა და დამუშავებისთვის გამოვიყენე Z-score მეთოდი. ჩამოვაშორე ის დაკვირვებები, რომელთა Z-ქულა აღემატებოდა 3-ს

## Training

### ტესტირებული მოდელები
შევადარე სამი ტიპის მოდელი, რომლებიც წარმოადგენენ სხვადასხვა fitting-ის ხარისხს:

1. **Underfitting მოდელები**
   - Constant Predictor (DummyRegressor) - ეს მოდელი უბრალოდ პროგნოზირებს საშუალო ფასს ყველა დაკვირვებისთვის

2. **Properly-fitted მოდელები**
   - Linear Regression - სტანდარტული წრფივი რეგრესია
   - Ridge Regression - რეგულარიზაციით გაუმჯობესებული წრფივი რეგრესია

3. **Overfitting მოდელები**
   - Polynomial Regression (Degree 5) - მაღალი ხარისხის პოლინომიალური რეგრესია

### საბოლოო მოდელის შერჩევის დასაბუთება
მოდელების შეფასებისას ვაკვირდებოდი როგორც ტრენირების, ასევე ვალიდაციის შედეგებს. Constant Predictor-მა აჩვენა ძალიან დაბალი ეფექტურობა (R² ≈ 0), რაც მიუთითებს underfitting-ზე. Polynomial Regression-მა აჩვენა კარგი შედეგები ტრენირების მონაცემებზე (R² ≈ 0.9874), მაგრამ ცუდი შედეგები ვალიდაციის მონაცემებზე, რაც მიუთითებს  overfitting-ზე.

სიმარტივისა და საუკეთესო ვალიდაციის შედეგების გათვალისწინებით, ოპტიმალურ მოდელად შევარჩიე Linear Regression და Ridge Regression. ორივემ აჩვენა მსგავსი შედეგები ვალიდაციის მონაცემებზე (R² ≈ 0.8008) და გონივრული გავლენა ტრენირებისა და ვალიდაციის მეტრიკებს შორის.

## MLflow Tracking

### MLflow ექსპერიმენტების ბმული
ყველა ექსპერიმენტი იხილეთ: https://dagshub.com/egval20/ml_Assignment1.mlflow/#/experiments/0

### მონაცემთა ანალიზის ექსპერიმენტის შედეგები (data_exploration)

მონაცემთა კვლევის ფაზაში აღმოვაჩინე შემდეგი მნიშვნელოვანი ინფორმაცია:

**პარამეტრები (Parameters):**
- ტრენირების მონაცემთა ზომა (train_rows/train_columns): 1460 სტრიქონი, 81 სვეტი
- ტესტირების მონაცემთა ზომა (test_rows/test_columns): 1459 სტრიქონი, 80 სვეტი
- კატეგორიული ცვლადების რაოდენობა (categorical_features_count): 43
- ნაკლული მნიშვნელობების მქონე ველები (high_missing_features): ['LotFrontage', 'Alley', 'MasVnrType', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']
- მაქსიმალური ნაკლული მნიშვნელობების პროცენტი (max_missing_percent): 99.52%
- პოტენციური გამორიცხვადი წერტილების რაოდენობა (potential_outliers_count): 2

**სამიზნე ცვლადის მეტრიკები (SalePrice Metrics):**
- საშუალო (target_mean): $180,921.20
- მედიანა (target_median): $163,000.00
- მინიმუმი (target_min): $34,900.00
- მაქსიმუმი (target_max): $755,000.00
- სტანდარტული გადახრა (target_std): $79,442.50
- ასიმეტრიულობა (target_skewness): 1.88 (დადებითად გადახრილი)

### ნიშნების შერჩევის ექსპერიმენტის შედეგები (Feature_Selection_Model)

**პარამეტრები (Parameters):**
- საწყისი ნიშნების რაოდენობა (initial_features_count): 79
- საბოლოო ნიშნების რაოდენობა (final_features_count): 10
- ერთნაირი მნიშვნელობების ზღვარი (threshold_same_values): 0.9
- ნაკლული მნიშვნელობების ზღვარი (threshold_missing_values): 0.95
- გამორიცხვადი წერტილების Z-score ზღვარი (outlier_z_score_threshold): 3
- ფილტრაციის შემდეგ დარჩენილი სემპლების რაოდენობა (samples_after_filtering): 1303
- საბოლოო ნიშნები (final_features): ['GrLivArea', 'OverallQual', 'YearBuilt', 'BedroomAbvGr', 'FullBath', 'GarageCars', 'LotArea', 'BldgType', 'SaleCondition', 'SalePrice']

### ჩაწერილი მოდელების შედეგები

#### Underfitting მოდელი (Constant Predictor)
- **ტრენირების მეტრიკები (Training Metrics)**:
  - RMSE (train_RMSE): 65,913.11
  - MAE (train_MAE): 50,783.77
  - R² (train_R2): 0.0000

- **ვალიდაციის მეტრიკები (Validation Metrics)**:
  - RMSE (val_RMSE): 65,698.45
  - MAE (val_MAE): 50,239.81
  - R² (val_R2): -0.0208

- **სხვაობის მეტრიკები (Gap Metrics)**:
  - RMSE_Gap: 214.67
  - R²_Gap: 0.0208

#### Overfitting მოდელი (Polynomial Regression Degree 5)
- **ტრენირების მეტრიკები (Training Metrics)**:
  - RMSE (train_RMSE): 7,403.42
  - MAE (train_MAE): 3,342.94
  - R² (train_R2): 0.9874

- **ვალიდაციის მეტრიკები (Validation Metrics)**:
  - RMSE (val_RMSE): 588,363,227.34
  - MAE (val_MAE): 108,254,137.59
  - R² (val_R2): -81,871,782.89

- **სხვაობის მეტრიკები (Gap Metrics)**:
  - RMSE_Gap: -588,355,823.92
  - R²_Gap: 81,871,783.88

#### Properly-fitted მოდელები

##### Linear Regression
- **ტრენირების მეტრიკები (Training Metrics)**:
  - RMSE (train_RMSE): 26,841.45
  - MAE (train_MAE): 20,119.51
  - R² (train_R2): 0.8342

- **ვალიდაციის მეტრიკები (Validation Metrics)**:
  - RMSE (val_RMSE): 29,019.60
  - MAE (val_MAE): 21,429.81
  - R² (val_R2): 0.8008

- **სხვაობის მეტრიკები (Gap Metrics)**:
  - RMSE_Gap: -2,178.14
  - R²_Gap: 0.0333

##### Ridge Regression (საუკეთესო მოდელი)
- **ტრენირების მეტრიკები (Training Metrics)**:
  - RMSE (train_RMSE): 26,841.51
  - MAE (train_MAE): 20,115.88
  - R² (train_R2): 0.8342

- **ვალიდაციის მეტრიკები (Validation Metrics)**:
  - RMSE (val_RMSE): 29,018.16
  - MAE (val_MAE): 21,429.26
  - R² (val_R2): 0.8008

- **სხვაობის მეტრიკები (Gap Metrics)**:
  - RMSE_Gap: -2,176.64
  - R²_Gap: 0.0333

### დასკვნა

კვლევის შედეგად, Ridge Regression აღმოჩნდა საუკეთესო მოდელი მცირედი უპირატესობით Linear Regression-ის მიმართ. ორივე მოდელმა აჩვენა კარგი ბალანსი ტრენირებისა და ვალიდაციის შედეგებს შორის (R² ≈ 0.83 ტრენირებაზე და R² ≈ 0.80 ვალიდაციაზე), რაც მიუთითებს, რომ მოდელები არც ზედმეტად მარტივია (underfitting) და არც ზედმეტად რთული (overfitting).

Ridge Regression-ის უპირატესობა მდგომარეობს იმაში, რომ მას აქვს ოდნავ უკეთესი ვალიდაციის RMSE (29,018.16 vs 29,019.60) და ოდნავ უკეთესი R² (0.8008 vs 0.8008), თუმცა განსხვავება მინიმალურია. მიუხედავად ამისა, Ridge Regression უზრუნველყოფს რეგულარიზაციას, რაც დამატებით სტაბილურობას ამატებს მოდელს train მონაცემების ცვლილებების მიმართ.
